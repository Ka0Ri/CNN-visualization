{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "from torchvision.datasets.mnist import FashionMNIST\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "import math\n",
    "\n",
    "print(torch.__version__)\n",
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class calTech(Dataset):\n",
    "    def __init__(self, name, transform=None):\n",
    "        hf = h5py.File(name, 'r')\n",
    "        self.input_images = np.array(hf.get('features'))\n",
    "        self.input_labels = np.array(hf.get('labels')).astype(np.long)\n",
    "        self.transform = transform\n",
    "        hf.close()\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.input_images.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images = self.input_images[idx]\n",
    "        labels = self.input_labels[idx]\n",
    "        if self.transform is not None:\n",
    "            images = self.transform(images)\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CHANNEL = 3\n",
    "BATCH_SIZE = 1\n",
    "normalize = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "classes = [str(i) for i in range(102)]\n",
    "\n",
    "data_path = os.path.dirname(os.getcwd()) + \"/data/calTech/\"\n",
    "Train_data = calTech(data_path + \"train.h5\", transform=normalize)\n",
    "Train_dataloader = DataLoader(dataset=Train_data, batch_size = 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "\n",
    "class My_Model(nn.Module):\n",
    "    def __init__(self, input_channel=1, num_class=21):\n",
    "        super(My_Model, self).__init__()\n",
    "        self.model_ft = models.vgg16(pretrained=True)\n",
    "        set_parameter_requires_grad(self.model_ft, False) \n",
    "        #change FC\n",
    "        self.model_ft.classifier[6] = nn.Linear(4096, num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Perform the usual forward pass\n",
    "        x_class = self.model_ft(x)\n",
    "            \n",
    "        return F.softmax(x_class, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model = My_Model(num_class=102)\n",
    "_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "inv_normalize = transforms.Normalize([-0.485/0.229, -0.456/0.224, -0.406/0.225], [1/0.229, 1/0.224, 1/0.225])\n",
    "\n",
    "def tensor_to_img(t):\n",
    "    \"\"\"Convert normalized tensor in Cuda to cv2 image\"\"\"\n",
    "    unnormalized = inv_normalize(t)\n",
    "    npimg = np.transpose(unnormalized.cpu().numpy(), (1, 2, 0))\n",
    "    return npimg\n",
    "\n",
    "def img_to_cuda_tensor(img):\n",
    "    tr_img = np.transpose(img, (2, 0, 1))\n",
    "    t = torch.from_numpy(tr_img)\n",
    "    t = normalize(t.float())\n",
    "    return t.to(device)\n",
    "    \n",
    "\n",
    "def imshow(img, title):\n",
    "    \"\"\"Custom function to display the image using matplotlib\"\"\"    \n",
    "    npimg = tensor_to_img(img)\n",
    "    #plot the numpy image\n",
    "    plt.figure(figsize = (4, 4))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(npimg)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def imshow_multi(list_img, title = None, n_cols = 5):\n",
    "    n_rows = math.ceil((len(list_img))/n_cols)\n",
    "    fig, axes = plt.subplots(n_rows,n_cols, figsize=(4*n_cols,4*n_rows))\n",
    "    for i,ax in enumerate(axes.flat):\n",
    "        ax.grid(False)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        if i>=len(list_img):\n",
    "            continue\n",
    "        if(title != None):\n",
    "            ax.set_title(\"layer \" + str(title[i]))\n",
    "\n",
    "        ax.imshow(list_img[i])\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveFeatures():\n",
    "    \"\"\"hook function at forward step\"\"\"\n",
    "    def __init__(self, module):\n",
    "        self.hook = module.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.features = output\n",
    "    def close(self):\n",
    "        self.hook.remove()\n",
    "\n",
    "class InvertedRepresentation():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "\n",
    "    def alpha_norm(self, input_matrix, alpha):\n",
    "        \"\"\"\n",
    "            Normal norm\n",
    "        \"\"\"\n",
    "        alpha_norm = ((input_matrix.view(-1))**alpha).sum()\n",
    "        return alpha_norm\n",
    "\n",
    "    def total_variation_norm(self, input_matrix, beta):\n",
    "        \"\"\"\n",
    "            Total variation norm\n",
    "        \"\"\"\n",
    "        to_check = input_matrix[:, :-1, :-1]  # Trimmed: right - bottom\n",
    "        one_bottom = input_matrix[:, 1:, :-1]  # Trimmed: top - right\n",
    "        one_right = input_matrix[:, :-1, 1:]  # Trimmed: top - right\n",
    "        total_variation = (((to_check - one_bottom)**2 +\n",
    "                            (to_check - one_right)**2)**(beta/2)).sum()\n",
    "        return total_variation\n",
    "\n",
    "    def euclidian_loss(self, org_matrix, target_matrix):\n",
    "        \"\"\"\n",
    "            Normalized Euclidian loss ||fi(x) - fi(x_0)||_2^2& / ||fi(x_0)||_2^2\n",
    "        \"\"\"\n",
    "        distance_matrix = target_matrix - org_matrix\n",
    "        euclidian_distance = self.alpha_norm(distance_matrix, 2)\n",
    "        normalized_euclidian_distance = euclidian_distance / self.alpha_norm(org_matrix, 2)\n",
    "        return normalized_euclidian_distance\n",
    "\n",
    "    def get_activations(self, x, layer_id):\n",
    "        \"\"\"\n",
    "            get feature maps\n",
    "        \"\"\"\n",
    "        \n",
    "        activations = SaveFeatures(self.model.model_ft.features[layer_id])\n",
    "        output = self.model(x)\n",
    "        feature_map = activations.features[0]\n",
    "        return feature_map\n",
    "\n",
    "    def generate_inverted_image(self, input_image, alpha = (6, 1e-7), beta = (2, 1e-8) ,target_layer=3):\n",
    "        # Generate a random image which we will optimize\n",
    "        input_image = input_image.to(device).float()\n",
    "        img_size = input_image.size(2)\n",
    "        \n",
    "        rand_img = torch.randn(1, 3, img_size, img_size).to(device)\n",
    "        opt_img = Variable(1e-1 * rand_img, requires_grad=True)\n",
    "        \n",
    "        optimizer = torch.optim.SGD([opt_img], lr=1e4, momentum=0.9)\n",
    "        \n",
    "        # Get the output with the real input image\n",
    "        input_image_layer_output = self.get_activations(input_image, target_layer)\n",
    "\n",
    "        # Alpha regularization parametrs\n",
    "        alpha_reg_alpha, alpha_reg_lambda = alpha\n",
    "       \n",
    "        # Total variation regularization parameters\n",
    "        tv_reg_beta, tv_reg_lambda = beta\n",
    "       \n",
    "        recreated_im = []\n",
    "        for i in (range(200)):\n",
    "            optimizer.zero_grad()\n",
    "            # Get the output with the random input image\n",
    "            output = self.get_activations(opt_img, target_layer)\n",
    "            # Calculate euclidian loss\n",
    "            euc_loss = 1e-1 * self.euclidian_loss(input_image_layer_output.detach(), output)\n",
    "            # Calculate alpha regularization\n",
    "            reg_alpha = alpha_reg_lambda * self.alpha_norm(opt_img, alpha_reg_alpha)\n",
    "            # Calculate total variation regularization\n",
    "            reg_total_variation = tv_reg_lambda * self.total_variation_norm(opt_img, tv_reg_beta)\n",
    "            # Sum all to optimize (all channels)\n",
    "            loss = euc_loss + reg_alpha + reg_total_variation\n",
    "            \n",
    "            # Step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # save image every 5 iterations\n",
    "            if i % 5 == 0:\n",
    "                recreated_im.append(tensor_to_img(opt_img.data[0]))\n",
    "            # Reduce learning rate every 40 iterations\n",
    "            if i % 40 == 0:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] *= 1/10\n",
    "        #print('Loss:', loss.item())\n",
    "        \n",
    "        return recreated_im\n",
    "    \n",
    "def reconstruct_single_layer(inv, input_image, alpha = (6, 1e-6), beta = (2, 1e-6), target_layers=[3]):\n",
    "    list_reconstruct = []\n",
    "    for layer_index in target_layers:\n",
    "        reconstructs = inv.generate_inverted_image(input_image, alpha, beta, target_layer = layer_index)\n",
    "        list_reconstruct.append(reconstructs[-1])\n",
    "    imshow_multi(list_reconstruct, title=target_layers)\n",
    "    \n",
    "    return list_reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = InvertedRepresentation(_model)\n",
    "\n",
    "input_image, label = next(iter(Train_dataloader))\n",
    "imshow(input_image[0], classes[label])\n",
    "re = reconstruct_single_layer(inv, input_image, target_layers = range(0, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_image, label = next(iter(Train_dataloader))\n",
    "imshow(input_image[0], classes[label])\n",
    "re = reconstruct_single_layer(inv, input_image, target_layers = range(0, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image, label = next(iter(Train_dataloader))\n",
    "imshow(input_image[0], classes[label])\n",
    "re = reconstruct_single_layer(inv, input_image, target_layers = range(0, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image, label = next(iter(Train_dataloader))\n",
    "imshow(input_image[0], classes[label])\n",
    "re = reconstruct_single_layer(inv, input_image, target_layers = range(0, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image, label = next(iter(Train_dataloader))\n",
    "imshow(input_image[0], classes[label])\n",
    "re = reconstruct_single_layer(inv, input_image, target_layers = range(0, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
