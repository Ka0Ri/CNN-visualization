{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "print(torch.__version__)\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "inv_normalize = transforms.Normalize([-0.485/0.229, -0.456/0.224, -0.406/0.225], [1/0.229, 1/0.224, 1/0.225])\n",
    "\n",
    "def tensor_to_img(t):\n",
    "    \"\"\"Convert normalized tensor in Cuda to cv2 image\"\"\"\n",
    "    unnormalized = inv_normalize(t)\n",
    "    npimg = np.transpose(unnormalized.cpu().numpy(), (1, 2, 0))\n",
    "    npimg[npimg > 1] = 1\n",
    "    npimg[npimg < 0] = 0\n",
    "    npimg = np.uint8(np.round(npimg*255))\n",
    "    return npimg\n",
    "\n",
    "def img_to_cuda_tensor(img):\n",
    "    img = img / 255.\n",
    "    tr_img = np.transpose(img, (2, 0, 1))\n",
    "    t = torch.from_numpy(tr_img)\n",
    "    t = normalize(t.float())\n",
    "    return t.to(device)\n",
    "    \n",
    "\n",
    "def imshow(img, title):\n",
    "    \"\"\"Custom function to display the image using matplotlib\"\"\"    \n",
    "    npimg = tensor_to_img(img)\n",
    "    #plot the numpy image\n",
    "    plt.figure(figsize = (4, 4))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(npimg)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def imshow_multi(list_img, title = None, n_cols = 5):\n",
    "    n_rows = math.ceil((len(list_img))/n_cols)\n",
    "    fig, axes = plt.subplots(n_rows,n_cols, figsize=(4*n_cols,4*n_rows))\n",
    "    for i,ax in enumerate(axes.flat):\n",
    "        ax.grid(False)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        if i>=len(list_img):\n",
    "            continue\n",
    "        if(title != None):\n",
    "            ax.set_title(\"layer \" + str(title[i]))\n",
    "\n",
    "        ax.imshow(list_img[i])\n",
    "        \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "class My_Model(nn.Module):\n",
    "    def __init__(self, input_channel=1, num_class=21, num_family = 5):\n",
    "        super(My_Model, self).__init__()\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        self.model_ft = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "        set_parameter_requires_grad(self.model_ft, False)\n",
    "\n",
    "        self.family_fc = nn.Linear(512, num_family)\n",
    "        self.class_fc = nn.Linear(512, num_class)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Perform the usual forward pass\n",
    "        x = self.model_ft(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x_class = self.class_fc(x)\n",
    "        x_family = self.family_fc(x)\n",
    "        return F.softmax(x_class, dim=1), F.softmax(x_family, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_model = My_Model(num_class=21, num_family = 5)\n",
    "_model.to(device)\n",
    "_model.load_state_dict(torch.load('epochs/ResNet18-base-line.pt'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveFeatures():\n",
    "    \"\"\"hook function at forward step\"\"\"\n",
    "    def __init__(self, module):\n",
    "        self.hook = module.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.features = output\n",
    "    def close(self):\n",
    "        self.hook.remove()\n",
    "\n",
    "class ClassSpecificImageGeneration():\n",
    "    \"\"\"\n",
    "        Produces an image that maximizes a certain class with gradient ascent\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.activations = SaveFeatures(model.class_fc)\n",
    "     \n",
    "\n",
    "    def generate(self, target_class = 0, sz =128, opt_steps=160):\n",
    "        rand_img = np.uint8(np.random.random((sz, sz, 3)) * 20 + 128.)\n",
    "        recreated_im = []\n",
    "        # Define optimizer for the image\n",
    "        \n",
    "        for n in range(0, opt_steps):\n",
    "            rand_img = img_to_cuda_tensor(rand_img)\n",
    "            opt_img = Variable(rand_img[None, :], requires_grad=True)\n",
    "            optimizer = torch.optim.SGD([opt_img], lr=1)\n",
    "            # Forward\n",
    "            output = self.model(opt_img)\n",
    "            # Target specific class\n",
    "            class_loss = -self.activations.features[0, target_class] + 0.01*torch.sum(torch.abs(opt_img))\n",
    "            # Backward\n",
    "            self.model.zero_grad()\n",
    "            class_loss.backward()\n",
    "            optimizer.step()\n",
    "            # Recreate image\n",
    "            rand_img = tensor_to_img(opt_img.data[0])\n",
    "            \n",
    "            rand_img = cv2.GaussianBlur(rand_img, (3, 3), 1)\n",
    "            if(n % 10 == 0):\n",
    "                recreated_im.append(rand_img)\n",
    "                \n",
    "        return recreated_im"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_model = models.vgg16(pretrained=True)\n",
    "_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = ClassSpecificImageGeneration(_model)\n",
    "for i in range(21):\n",
    "    reconstructs = inv.generate(target_class = i)\n",
    "    cv2.imwrite(\"weed_classes/\" + str(i) + \".png\", reconstructs[-1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inv = ClassSpecificImageGeneration(_model)\n",
    "reconstructs = inv.generate(target_class = 1)\n",
    "imshow_multi(reconstructs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
